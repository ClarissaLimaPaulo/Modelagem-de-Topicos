{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DISCLAIMER/AVISO**\n",
        "\n",
        "O script a seguir é uma junção do script obtido pelo Chat GPT (a partir do prompt: \"Como uso a LDA no Python?\"), com adições e trocas a partir de sugestões do Gemini, que reformulou algumas linhas de acordo com o nosso arquivo. Portanto, que fique claro que esse script não foi escrito por nenhum membro desse grupo."
      ],
      "metadata": {
        "id": "UVR8_12LyjqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(1) Instalar as bibliotecas**"
      ],
      "metadata": {
        "id": "GsqR3Ci8zC1K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zETxDiK9Fqhp"
      },
      "outputs": [],
      "source": [
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install pandas\n",
        "!pip install -U pyLDAvis\n",
        "!pip install pyLDAvis==3.4.1\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(2) Importar as bibliotecas**"
      ],
      "metadata": {
        "id": "sPrHC4ItzJgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import pyLDAvis\n",
        "from pyLDAvis import gensim\n",
        "import pyLDAvis.gensim"
      ],
      "metadata": {
        "id": "DbcyTMuEC3fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2.1) Importando a library Natural Language Toolkit - NLTK para tratamento de linguagem natural\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "mdbZXscwznzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(3) Abrindo e lendo a planilha**"
      ],
      "metadata": {
        "id": "2CgqUw-3zPYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('terceirarodada_LDA.xlsx')\n",
        "\n",
        "nomes_colunas = [\"key\", \"jornal\", \"transcrito\"]"
      ],
      "metadata": {
        "id": "3NTP9WPLC5_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(4) Criando o dicionário e o corpus**"
      ],
      "metadata": {
        "id": "PtwGWjYS0LOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.1) Criar o dicionário (mapear palavras a IDs)\n",
        "\n",
        "dictionary = corpora.Dictionary(df['transcrito'].apply(lambda x: x.split()))"
      ],
      "metadata": {
        "id": "OfjIKuYlDY_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.2) Criar o corpus (conjunto de documentos em formato vetorial)\n",
        "\n",
        "corpus = [dictionary.doc2bow(doc) for doc in df['transcrito'].apply(lambda x: x.split())]"
      ],
      "metadata": {
        "id": "NMWuqWbH0Vx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(5) Treinando o modelo LDA**"
      ],
      "metadata": {
        "id": "wPAYqUmu0b3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.1) Definir o número de tópicos\n",
        "num_topics = 5"
      ],
      "metadata": {
        "id": "5lQTGEV0DpDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.2) Treinar o modelo LDA\n",
        "\n",
        "import gensim\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus,\n",
        "    num_topics=num_topics,\n",
        "    id2word=dictionary,\n",
        "    passes=15\n",
        ")"
      ],
      "metadata": {
        "id": "qqNe00Mq0irw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(6) Visualizar os tópicos**"
      ],
      "metadata": {
        "id": "tIiHORmo0lsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Tópico {idx}: {topic}\")\n"
      ],
      "metadata": {
        "id": "J665XSNtDtOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(7) Tabulando a distribuição dos tópicos para cada documento**"
      ],
      "metadata": {
        "id": "aebtxj7Y0vp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.1) Para cada documento, pegar a distribuição dos tópicos\n",
        "topic_distribution = []\n",
        "\n",
        "for doc in corpus:\n",
        "    doc_topics = lda_model.get_document_topics(doc, minimum_probability=0)\n",
        "    topic_distribution.append([prob for _, prob in doc_topics])"
      ],
      "metadata": {
        "id": "gP54g1r1DwgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.2) Criar um DataFrame com essa distribuição\n",
        "\n",
        "df_topic_distribution = pd.DataFrame(topic_distribution, columns=[f'Tópico {i+1}' for i in range(num_topics)])"
      ],
      "metadata": {
        "id": "haavWOUA04ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.3) Exibir a tabela\n",
        "\n",
        "print(df_topic_distribution)"
      ],
      "metadata": {
        "id": "JQ2L8dr80-NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(8) Visualização dos dados**"
      ],
      "metadata": {
        "id": "Y2R_xR071U64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "from pyLDAvis import gensim\n",
        "\n",
        "lda_display = gensim.prepare(lda_model, corpus, dictionary)\n",
        "\n",
        "pyLDAvis.save_html(lda_display, 'lda_visualization.html')\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(lda_display)"
      ],
      "metadata": {
        "id": "Jjp1fij-EPBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(9) Baixando o arquivo**"
      ],
      "metadata": {
        "id": "6KS0frwH18fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('lda_visualization.html')"
      ],
      "metadata": {
        "id": "kNz-uuNeFmoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

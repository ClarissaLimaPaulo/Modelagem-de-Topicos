{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DISCLAIMER/AVISO**\n",
        "\n",
        "O script a seguir é uma junção do script obtido pelo Chat GPT (a partir do prompt: faça um código para tokenização em python), com adições e trocas a partir de sugestões do Gemini, que reformulou algumas linhas de acordo com o nosso arquivo. Portanto, que fique claro que esse script não foi escrito por nenhum membro desse grupo."
      ],
      "metadata": {
        "id": "L4M4k8HDCaD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(1) Instalar as bibliotecas**\n"
      ],
      "metadata": {
        "id": "2iIU8tqYCi_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ldAsJJOD2EQ"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(2) Carregar as bibliotecas**\n"
      ],
      "metadata": {
        "id": "5u95hoa0DA1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import spacy"
      ],
      "metadata": {
        "id": "6h6MG7RlEHjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2.1) Importando a library Natural Language Toolkit - NLTK para tratamento de linguagem natural\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.util import ngrams\n"
      ],
      "metadata": {
        "id": "V68sOPscEKwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2.2) Baixando o tokenizer no padrão NLTK\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "eSISmhmHoQqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(3) Abrindo e lendo a planilha**"
      ],
      "metadata": {
        "id": "kyRRgPu8Y4Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/MODELAGEM_TESTE.xlsx')\n",
        "\n",
        "nomes_colunas = [\"key\", \"transcrito\"]\n",
        "\n",
        "df = pd.read_excel\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pRJWl4NfolKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(4) Tokenizando o texto**"
      ],
      "metadata": {
        "id": "uH9XS5LaZ725"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.1) Carregando o modelo de linguagem spaCy na língua portuguesa\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')"
      ],
      "metadata": {
        "id": "UB581goIZ0Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.2) Função para tokenizar o texto\n",
        "\n",
        "def tokenize_text(text):\n",
        "  doc = nlp(text)\n",
        "  return ' '.join([token.lemma_ for token in doc])\n"
      ],
      "metadata": {
        "id": "8VduBpLNoS9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.3) Aplica a função de tokenização à coluna do corpus textual\n",
        "\n",
        "df['transcrito_Tokenizado'] = df['transcrito'].apply(tokenize_text)"
      ],
      "metadata": {
        "id": "BJdjR6V3pvI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.4) Exibir os resultados com a coluna tokenizada\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Azj0oI2Tpz03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(5) Limpando o texto com a retirada de caracteres específicos**\n",
        "\n"
      ],
      "metadata": {
        "id": "BLx__DqhaoWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.1) Função para tirar números\n",
        "\n",
        "def remove_numbers(text):\n",
        "  text_without_numbers = re.sub(r'\\d+', '', text)\n",
        "  return text_without_numbers\n",
        "\n",
        "# (5.2) Aplicando essa função nas células do corpus textual\n",
        "\n",
        "df['transcrito_sem_numeros'] = df['transcrito'].apply(remove_numbers)\n",
        "\n",
        "# (5.3) Exibindo resultados com a coluna sem os números\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "uA7VeNP4qWDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.4) Mesmo processo, mas com aspas\n",
        "\n",
        "def remove_quotes(text):\n",
        "  text_without_quotes = text.replace('\"', '')\n",
        "  return text_without_quotes\n",
        "\n",
        "df['transcrito_sem_aspas'] = df['transcrito_sem_numeros'].apply(remove_quotes)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "jX5Qp0SdqiAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.5) Mesmo processo, mas com preposições\n",
        "\n",
        "def remove_proposicoes(text):\n",
        "  text_without_proposicoes = re.sub(r'(Proposição|proposição|PROPOSIÇÃO)\\s*\\w+', '', text)\n",
        "  return text_without_proposicoes\n",
        "\n",
        "df['transcrito_sem_proposicoes'] = df['transcrito_sem_aspas'].apply(remove_proposicoes)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "02hJ4iH6qpR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.6) Mesmo processo, mas com stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
        "  return ' '.join(filtered_text)\n",
        "\n",
        "df['transcrito_sem_stopwords'] = df['transcrito_sem_aspas'].apply(remove_stopwords)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "BP_fxkH6rAco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.7) Mesmo processo, mas deixando tudo com letra minúscula\n",
        "\n",
        "def lowercase_text(text):\n",
        "  lowercased_text = text.lower()\n",
        "  return lowercased_text\n",
        "\n",
        "df['transcrito_minusculo'] = df['transcrito_sem_stopwords'].apply(lowercase_text)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "WSRsbV4brkd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.8) Mesmo processo, mas para tirar espaços duplicados\n",
        "\n",
        "def remove_extra_whitespaces(text):\n",
        "  return ' '.join(text.split())\n",
        "\n",
        "df['transcrito_sem_espacos_extras'] = df['transcrito_minusculo'].apply(remove_extra_whitespaces)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "i-m41qFRruw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.8) Mesmo processo, mas para tirar vírgulas\n",
        "\n",
        "def remove_commas(text):\n",
        "  text_without_commas = text.replace(',', '')\n",
        "  return text_without_commas\n",
        "\n",
        "df['transcrito_sem_virgulas'] = df['transcrito_sem_espacos_extras'].apply(remove_commas)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "H9NOt6FTr0dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.8) Mesmo processo, mas para tirar termos que não são palavras\n",
        "\n",
        "def remove_non_words(text):\n",
        "  text_with_only_words = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  return text_with_only_words\n",
        "\n",
        "df['transcrito_somente_palavras'] = df['transcrito_sem_virgulas'].apply(remove_non_words)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "84WhVzgusu7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(6) Juntando termos**"
      ],
      "metadata": {
        "id": "zxHFWqwDbyXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.1) Função para juntar os termos \"jose\" e \"serra\" com underline\n",
        "\n",
        "def join_jose_serra(text):\n",
        "  return text.replace('jose serra', 'jose_serra')\n",
        "\n",
        "# (6.2) Aplicando essa função nas células do corpus textual\n",
        "\n",
        "df['transcrito_jose_serra_junto'] = df['transcrito_sem_virgulas'].apply(join_jose_serra)\n",
        "\n",
        "# (6.3) Exibindo os resultados\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "fkXgU1zP12D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.4) Mesmo processo, mas para juntar os termos \"universidade\", \"de\", \"sao\", \"paulo\" com underline\n",
        "\n",
        "def join_universidade_sao_paulo(text):\n",
        "  return text.replace('universidade de sao paulo', 'universidade_de_sao_paulo')\n",
        "\n",
        "df['transcrito_universidade_sao_paulo_junto'] = df['transcrito_jose_serra_junto'].apply(join_universidade_sao_paulo)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "rg189uxU2Bjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.5) Mesmo processo, mas para juntar vários termos de uma vez com underline (movimento+estudantil; suely+vilela; ministerio+publico; ordem+juridico; moradia+estudantil)\n",
        "\n",
        "def join_movimento_estudantil(text):\n",
        "  return text.replace('movimento estudantil', 'movimento_estudantil')\n",
        "\n",
        "def join_suely_vilela(text):\n",
        "  return text.replace('suely vilela', 'suely_vilela')\n",
        "\n",
        "def join_ministerio_publico(text):\n",
        "  return text.replace('ministerio publico', 'ministerio_publico')\n",
        "\n",
        "def join_ordem_juridico(text):\n",
        "  return text.replace('ordem juridico', 'ordem_juridico')\n",
        "\n",
        "def join_moradia_estudantil(text):\n",
        "  return text.replace('moradia estudantil', 'moradia_estudantil')\n",
        "\n",
        "df['transcrito_movimento_estudantil_junto'] = df['transcrito_universidade_sao_paulo_junto'].apply(join_movimento_estudantil)\n",
        "df['transcrito_suely_vilela_junto'] = df['transcrito_movimento_estudantil_junto'].apply(join_suely_vilela)\n",
        "df['transcrito_ministerio_publico_junto'] = df['transcrito_suely_vilela_junto'].apply(join_ministerio_publico)\n",
        "df['transcrito_ordem_juridico_junto'] = df['transcrito_ministerio_publico_junto'].apply(join_ordem_juridico)\n",
        "df['transcrito_moradia_estudantil_junto'] = df['transcrito_ordem_juridico_junto'].apply(join_moradia_estudantil)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zGLR0fIJ2Lht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.6) Mesmo processo, mas para juntar vários termos de uma vez com underline (franco+lajolo; universidade+publico; grupo+politico; vice+reitor; assembleia+legislativa; jose+aristodemo+pinotti; cidade+universitaria; professor+titular; decisao+judicial; policia+militar; policial+militar)\n",
        "\n",
        "\n",
        "def join_franco_lajolo(text):\n",
        "  return text.replace('franco lajolo', 'franco_lajolo')\n",
        "\n",
        "def join_universidade_publica(text):\n",
        "  return text.replace('universidade publica', 'universidade_publica')\n",
        "\n",
        "def join_grupo_politico(text):\n",
        "  return text.replace('grupo politico', 'grupo_politico')\n",
        "\n",
        "def join_vice_reitor(text):\n",
        "  return text.replace('vice reitor', 'vice_reitor')\n",
        "\n",
        "def join_assembleia_legislativa(text):\n",
        "  return text.replace('assembleia legislativa', 'assembleia_legislativa')\n",
        "\n",
        "def join_jose_aristodemo_pinotti(text):\n",
        "  return text.replace('jose aristodemo pinotti', 'jose_aristodemo_pinotti')\n",
        "\n",
        "def join_cidade_universitaria(text):\n",
        "  return text.replace('cidade universitaria', 'cidade_universitaria')\n",
        "\n",
        "def join_professor_titular(text):\n",
        "  return text.replace('professor titular', 'professor_titular')\n",
        "\n",
        "def join_decisao_judicial(text):\n",
        "  return text.replace('decisao judicial', 'decisao_judicial')\n",
        "\n",
        "def join_policia_militar(text):\n",
        "  return text.replace('policia militar', 'policia_militar')\n",
        "\n",
        "def join_policial_militar(text):\n",
        "  return text.replace('policial militar', 'policial_militar')\n",
        "\n",
        "df['transcrito_franco_lajolo_junto'] = df['transcrito_moradia_estudantil_junto'].apply(join_franco_lajolo)\n",
        "df['transcrito_universidade_publica_junto'] = df['transcrito_franco_lajolo_junto'].apply(join_universidade_publica)\n",
        "df['transcrito_grupo_politico_junto'] = df['transcrito_universidade_publica_junto'].apply(join_grupo_politico)\n",
        "df['transcrito_vice_reitor_junto'] = df['transcrito_grupo_politico_junto'].apply(join_vice_reitor)\n",
        "df['transcrito_assembleia_legislativa_junto'] = df['transcrito_vice_reitor_junto'].apply(join_assembleia_legislativa)\n",
        "df['transcrito_jose_aristodemo_pinotti_junto'] = df['transcrito_assembleia_legislativa_junto'].apply(join_jose_aristodemo_pinotti)\n",
        "df['transcrito_cidade_universitaria_junto'] = df['transcrito_jose_aristodemo_pinotti_junto'].apply(join_cidade_universitaria)\n",
        "df['transcrito_professor_titular_junto'] = df['transcrito_cidade_universitaria_junto'].apply(join_professor_titular)\n",
        "df['transcrito_decisao_judicial_junto'] = df['transcrito_professor_titular_junto'].apply(join_decisao_judicial)\n",
        "df['transcrito_policia_militar_junto'] = df['transcrito_decisao_judicial_junto'].apply(join_policia_militar)\n",
        "df['transcrito_policial_militar_junto'] = df['transcrito_policia_militar_junto'].apply(join_policial_militar)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "PUW1kTmx2iBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.7) Mesmo processo, mas para juntar vários termos de uma vez com underline (sindicato+trabalhadores; tropa+choque; escola+politecnica; faculdade+economia+administracao; faculdade+odontologia; faculdade+medicina; instituto+fisica; faculdade+filosofia+letras+ciencias+humanas)\n",
        "\n",
        "\n",
        "def join_sindicato_trabalhadores(text):\n",
        "  return text.replace('sindicato dos trabalhadores', 'sindicato_dos_trabalhadores')\n",
        "\n",
        "def join_tropa_choque(text):\n",
        "  return text.replace('tropa de choque', 'tropa_de_choque')\n",
        "\n",
        "def join_escola_politecnica(text):\n",
        "  return text.replace('escola politecnica', 'escola_politecnica')\n",
        "\n",
        "def join_faculdade_economia_administracao(text):\n",
        "  return text.replace('faculdade de economia administracao', 'faculdade_de_economia_administracao')\n",
        "\n",
        "def join_faculdade_odontologia(text):\n",
        "  return text.replace('faculdade de odontologia', 'faculdade_de_odontologia')\n",
        "\n",
        "def join_faculdade_medicina(text):\n",
        "  return text.replace('faculdade de medicina', 'faculdade_de_medicina')\n",
        "\n",
        "def join_instituto_fisica(text):\n",
        "  return text.replace('instituto de fisica', 'instituto_de_fisica')\n",
        "\n",
        "def join_faculdade_filosofia_letras_ciencias_humanas(text):\n",
        "  return text.replace('faculdade de filosofia letras e ciencias humanas', 'faculdade_de_filosofia_letras_e_ciencias_humanas')\n",
        "\n",
        "df['transcrito_sindicato_trabalhadores_junto'] = df['transcrito_policial_militar_junto'].apply(join_sindicato_trabalhadores)\n",
        "df['transcrito_tropa_choque_junto'] = df['transcrito_sindicato_trabalhadores_junto'].apply(join_tropa_choque)\n",
        "df['transcrito_escola_politecnica_junto'] = df['transcrito_tropa_choque_junto'].apply(join_escola_politecnica)\n",
        "df['transcrito_faculdade_economia_administracao_junto'] = df['transcrito_escola_politecnica_junto'].apply(join_faculdade_economia_administracao)\n",
        "df['transcrito_faculdade_odontologia_junto'] = df['transcrito_faculdade_economia_administracao_junto'].apply(join_faculdade_odontologia)\n",
        "df['transcrito_faculdade_medicina_junto'] = df['transcrito_faculdade_odontologia_junto'].apply(join_faculdade_medicina)\n",
        "df['transcrito_instituto_fisica_junto'] = df['transcrito_faculdade_medicina_junto'].apply(join_instituto_fisica)\n",
        "df['transcrito_faculdade_filosofia_letras_ciencias_humanas_junto'] = df['transcrito_instituto_fisica_junto'].apply(join_faculdade_filosofia_letras_ciencias_humanas)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "XC81pbKf3LdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.8) Mesmo processo, mas para juntar vários termos de uma vez com underline (assessoria+imprensa; governo+estadual; ensino+medio; ensino+superior; ensino+superior+publico)\n",
        "\n",
        "def join_assessoria_imprensa(text):\n",
        "  return text.replace('assessoria de imprensa', 'assessoria_de_imprensa')\n",
        "\n",
        "def join_governo_estadual(text):\n",
        "  return text.replace('governo estadual', 'governo_estadual')\n",
        "\n",
        "def join_ensino_medio(text):\n",
        "  return text.replace('ensino medio', 'ensino_medio')\n",
        "\n",
        "def join_ensino_superior(text):\n",
        "  return text.replace('ensino superior', 'ensino_superior')\n",
        "\n",
        "def join_ensino_superior_publico(text):\n",
        "  return text.replace('ensino superior publico', 'ensino_superior_publico')\n",
        "\n",
        "df['transcrito_assessoria_imprensa_junto'] = df['transcrito_faculdade_filosofia_letras_ciencias_humanas_junto'].apply(join_assessoria_imprensa)\n",
        "df['transcrito_governo_estadual_junto'] = df['transcrito_assessoria_imprensa_junto'].apply(join_governo_estadual)\n",
        "df['transcrito_ensino_medio_junto'] = df['transcrito_governo_estadual_junto'].apply(join_ensino_medio)\n",
        "df['transcrito_ensino_superior_junto'] = df['transcrito_ensino_medio_junto'].apply(join_ensino_superior)\n",
        "df['transcrito_ensino_superior_publico_junto'] = df['transcrito_ensino_superior_junto'].apply(join_ensino_superior_publico)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "bPOHZJuM321X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.9) Mesmo processo, mas para juntar vários termos de uma vez com underline (mau+comportamento; geraldo+alckmin; sylvio+sawaya; faculdade+arquitetura+urbanismo; bodes+expiatorios; governador+serra; universidade+estadual+paulista; eduardo+suplicy; mignon+carvalho; zona+oeste; jornal+campus; diretorio+central+estudantes; centro+academico; escolas+tecnicas+estaduais; luiz+antonio+guimaraes+marrey)\n",
        "\n",
        "def join_mau_comportamento(text):\n",
        "  return text.replace('mau comportamento', 'mau_comportamento')\n",
        "\n",
        "def join_geraldo_alckmin(text):\n",
        "  return text.replace('geraldo alckmin', 'geraldo_alckmin')\n",
        "\n",
        "def join_sylvio_sawaya(text):\n",
        "  return text.replace('sylvio sawaya', 'sylvio_sawaya')\n",
        "\n",
        "def join_faculdade_arquitetura_urbanismo(text):\n",
        "  return text.replace('faculdade de arquitetura e urbanismo', 'faculdade_de_arquitetura_e_urbanismo')\n",
        "\n",
        "def join_bodes_expiatorios(text):\n",
        "  return text.replace('bodes expiatorios', 'bodes_expiatorios')\n",
        "\n",
        "def join_governador_serra(text):\n",
        "  return text.replace('governador serra', 'governador_serra')\n",
        "\n",
        "def join_universidade_estadual_paulista(text):\n",
        "  return text.replace('universidade estadual paulista', 'universidade_estadual_paulista')\n",
        "\n",
        "def join_eduardo_suplicy(text):\n",
        "  return text.replace('eduardo suplicy', 'eduardo_suplicy')\n",
        "\n",
        "def join_mignon_carvalho(text):\n",
        "  return text.replace('mignon carvalho', 'mignon_carvalho')\n",
        "\n",
        "def join_zona_oeste(text):\n",
        "  return text.replace('zona oeste', 'zona_oeste')\n",
        "\n",
        "def join_jornal_campus(text):\n",
        "  return text.replace('jornal campus', 'jornal_campus')\n",
        "\n",
        "def join_diretorio_central_estudantes(text):\n",
        "  return text.replace('diretorio central estudantes', 'diretorio_central_estudantes')\n",
        "\n",
        "def join_centro_academico(text):\n",
        "  return text.replace('centro academico', 'centro_academico')\n",
        "\n",
        "def join_centros_academicos(text):\n",
        "  return text.replace('centros academicos', 'centros_academicos')\n",
        "\n",
        "def join_escolas_tecnicas_estaduais(text):\n",
        "  return text.replace('escolas tecnicas estaduais', 'escolas_tecnicas_estaduais')\n",
        "\n",
        "def join_luiz_antonio_guimaraes_marrey(text):\n",
        "  return text.replace('luiz antonio guimaraes marrey', 'luiz_antonio_guimaraes_marrey')\n",
        "\n",
        "df['transcrito_mau_comportamento_junto'] = df['transcrito_ensino_superior_publico_junto'].apply(join_mau_comportamento)\n",
        "df['transcrito_geraldo_alckmin_junto'] = df['transcrito_mau_comportamento_junto'].apply(join_geraldo_alckmin)\n",
        "df['transcrito_sylvio_sawaya_junto'] = df['transcrito_geraldo_alckmin_junto'].apply(join_sylvio_sawaya)\n",
        "df['transcrito_faculdade_arquitetura_urbanismo_junto'] = df['transcrito_sylvio_sawaya_junto'].apply(join_faculdade_arquitetura_urbanismo)\n",
        "df['transcrito_bodes_expiatorios_junto'] = df['transcrito_faculdade_arquitetura_urbanismo_junto'].apply(join_bodes_expiatorios)\n",
        "df['transcrito_governador_serra_junto'] = df['transcrito_bodes_expiatorios_junto'].apply(join_governador_serra)\n",
        "df['transcrito_universidade_estadual_paulista_junto'] = df['transcrito_governador_serra_junto'].apply(join_universidade_estadual_paulista)\n",
        "df['transcrito_eduardo_suplicy_junto'] = df['transcrito_universidade_estadual_paulista_junto'].apply(join_eduardo_suplicy)\n",
        "df['transcrito_mignon_carvalho_junto'] = df['transcrito_eduardo_suplicy_junto'].apply(join_mignon_carvalho)\n",
        "df['transcrito_zona_oeste_junto'] = df['transcrito_mignon_carvalho_junto'].apply(join_zona_oeste)\n",
        "df['transcrito_jornal_campus_junto'] = df['transcrito_mignon_carvalho_junto'].apply(join_jornal_campus)\n",
        "df['transcrito_diretorio_central_estudantes_junto'] = df['transcrito_jornal_campus_junto'].apply(join_diretorio_central_estudantes)\n",
        "df['transcrito_centro_academico_junto'] = df['transcrito_diretorio_central_estudantes_junto'].apply(join_centro_academico)\n",
        "df['transcrito_centros_academicos_junto'] = df['transcrito_centro_academico_junto'].apply(join_centros_academicos)\n",
        "df['transcrito_escolas_tecnicas_estaduais_junto'] = df['transcrito_centros_academicos_junto'].apply(join_escolas_tecnicas_estaduais)\n",
        "df['transcrito_luiz_antonio_guimaraes_marrey_junto'] = df['transcrito_escolas_tecnicas_estaduais_junto'].apply(join_luiz_antonio_guimaraes_marrey)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NXTPpaKk4SU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(7) Limpando o texto retirando mais palavras específicas**"
      ],
      "metadata": {
        "id": "05Zho-RGeoJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.1) Função para tirar vários termos específicos de uma vez só (os termos são: segundo; afirmar; ter; ja; dia; ontem; tambem; hoje; desde; alem; hora; cujo; dizer; algum)\n",
        "\n",
        "def remove_words(text):\n",
        "  words_to_remove = ['segundo', 'afirmar', 'ter', 'ja', 'dia', 'ontem', 'tambem', 'hoje', 'desde', 'alem', 'hora', 'cujo', 'dizer', 'algum']\n",
        "  return ' '.join([word for word in text.split() if word not in words_to_remove])\n",
        "\n",
        "# (7.2) Aplicando essa função nas células do corpus textual\n",
        "\n",
        "df['transcrito_sem_palavras_especificas'] = df['transcrito_zona_oeste_junto'].apply(remove_words)\n",
        "\n",
        "# (7.3) Exibindo os resultados\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "r0D9dgTX5UhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.4) Mesmo processo, mas para tirar vários termos de uma vez com underline (semana; dar; todo; ir)\n",
        "\n",
        "def remove_specific_words(text):\n",
        "  words_to_remove = ['semana', 'dar', 'todo', 'ir']\n",
        "  return ' '.join([word for word in text.split() if word not in words_to_remove])\n",
        "\n",
        "df['transcrito_sem_palavras_especificas_2'] = df['transcrito_sem_palavras_especificas'].apply(remove_specific_words)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qi9cS9ovcBqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(8) Baixando o arquivo**"
      ],
      "metadata": {
        "id": "a0cjE0fKhNl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('Modelagem_TESTEfeito.xlsx', index=False)"
      ],
      "metadata": {
        "id": "-QmUw4wZ9NGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClarissaLimaPaulo/ClarissaLimaPaulo/blob/main/limpeza1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISCLAIMER/AVISO**"
      ],
      "metadata": {
        "id": "VC7mTmb68y3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O script a seguir é uma junção do script fornecido pela monitora Glória Carvalho da disciplina de Métodos e Técnicas de Pesquisa II, com adições e trocas a partir de sugestões do Gemini, que reformulou algumas linhas de acordo com o nosso arquivo. Portanto, que fique claro que esse script **não foi** escrito por nenhum membro desse grupo."
      ],
      "metadata": {
        "id": "vscmQ2sW8-u_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(1) Instalar as bibliotecas**"
      ],
      "metadata": {
        "id": "ElYJLmKY4Rw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!pip install nltk"
      ],
      "metadata": {
        "id": "_ncMgO7A481-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(2) Carregar as bibliotecas**"
      ],
      "metadata": {
        "id": "X9KQfF7R5CFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "yNTHKcKL5W3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(2.1) Importando a library Natural Language Toolkit - NLTK para tratamento de linguagem natural\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "w5INOtO0d892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2.2) Importar as stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('portuguese'))"
      ],
      "metadata": {
        "id": "etMuyYbreEnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(3) Abrindo e lendo a planilha**"
      ],
      "metadata": {
        "id": "-uzvs_YT56fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/MODELAGEM_TESTE.xlsx')\n",
        "\n",
        "nomes_colunas = [\"KEY\", \"TRANSCRITO\"]\n",
        "\n",
        "df = pd.read_excel\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "E_0O-dpUiczk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(4) Lematizando o texto**"
      ],
      "metadata": {
        "id": "LTXbGnU76G3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.1) Carregando o modelo de linguagem spaCy na língua portuguesa\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')"
      ],
      "metadata": {
        "id": "WNQxHnHsi7uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.2) Lematizar o texto\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)  # Processa o texto com spaCy\n",
        "    return ' '.join([token.lemma_ for token in doc])  # Retorna o texto lematizado"
      ],
      "metadata": {
        "id": "r1bwSwJWi9tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.3) Aplica a função de lematização à coluna do corpus textual\n",
        "\n",
        "df['Transcrito_Lematizado'] = df['Transcrito'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "8HLh9YCfjbCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4.4) Exibir os resultados com a coluna lematizada\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_VM2DXu-jjg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(5) Limpando o texto**"
      ],
      "metadata": {
        "id": "J0g7wgqX6aAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.1) Para retirar caracteres não ASCII\n",
        "\n",
        "def remove_non_ascii(word):\n",
        "    new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return new_word"
      ],
      "metadata": {
        "id": "zOaMhju4kG_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.2) Função para processar cada célula individualmente\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r\"\\'\", \"\", text)\n",
        "    text = text.lower()\n",
        "\n",
        "    words = text.split()\n",
        "    words = [remove_non_ascii(word) for word in words] # Fixed indentation here\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "4W91SCF2kV2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.3) Aplicar essa função a todas as células\n",
        "\n",
        "df['Transcrito_Processado'] = df['Transcrito_Lematizado'].apply(process_text)"
      ],
      "metadata": {
        "id": "VPkAabYplV7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.4) Exibir os resultados com a coluna limpa\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YjBLQrnvlbIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(6) Removendo as stopwords**"
      ],
      "metadata": {
        "id": "nVdVOBC57Oc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords_and_non_ascii(text):\n",
        "    words = text.split()\n",
        "    words_without_stopwords = [word for word in words if word not in stopwords]\n",
        "    cleaned_text = \" \".join(words_without_stopwords)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "_BSX9k1TlmID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.1) Aplicando a função remove_stopwords_and_non_ascii à coluna 'Transcrito_Processado'\n",
        "\n",
        "df['Transcrito_Limpo'] = df['Transcrito_Processado'].apply(remove_stopwords_and_non_ascii)"
      ],
      "metadata": {
        "id": "ZmmmlAhqloY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6.2) Exibir os resultados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HoB3aANYlsli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(7) Baixando o arquivo**"
      ],
      "metadata": {
        "id": "jiOZkho88glF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (7.1) Salva no computador do usuário\n",
        "df.to_excel('Modelagem_TESTEfeito.xlsx', index=False)"
      ],
      "metadata": {
        "id": "_1fDW4qel7ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# (7.2) Importa direto como Google Sheets\n",
        "\n",
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=df)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "4l_Z9nRimKIk"
      }
    }
  ]
}
